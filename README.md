# Machine Learning projects


## Titanic Survival Predictions 
The titanic dataset is a classification problem in which the main goal is to classify passengers as either survived or dead. The ML models implemented in the notebook are Logistic Regression and Ensemble stacking, with extensive EDA and data preprocessing done.

## King Country Regression Analysis 
The King County dataset consists of predicting the final house price by taking in input features of various housing specifications and using them to develop a regression model to accurately forecast future house prices. The project made me use R and Python together to utilize R's power of statistical analysis and Python for its machine learning. 

## Ames Housing dataset Regression 
The Ames housing dataset is a much more complex variant of the King County dataset which consists of a lot more features of all types, ranging from categorical to numeric. With around 80 features and the predictor variable as the house price, the project included extensive data preprocessing, cleansing and included using regularization techniques in order to boost the predictive force of the models while ensuring the minimization of multicollinearity

## Bank Fraud Detection 
The bank fraud detection posed an anomaly detection problem where the goal was to predict the occurences of fraud transactions using machine learning. The problem posed a class imbalance problem which had to be fixed with class-resampling techniques and the detection of fraud cases was visualized using clustering techniques.

## PlayerUnknown's Battlegrounds Player Leaderboards Prediction 
The PUBG leaderboards prediction was the first "big" dataset I worked on, with a size of 1.5GB. With various in-game statistics used as input features, the goal was to predict the leaderboard standings of all player types in the game, ranging from solo, duo to squad player types. The machine learning problem employed a n-layered neural network to perform the predictions and produce results. 

## Don't Overfit Challenge 
The Don't Overfit challenge was one of the unique instances of data mining problems which focused on building a model on an extremely small dataset with around 250 observations and using that to run predictions on a dataset with 100x more observations. The dataset posed an overfitting challenge which had to be addressed using feature selection techniques and employing parsimonious models such as logistic regression. 

## Stock Market Classification 
Done as a part of my undergraduate thesis project, the goal of this project was to develop a predictive model which can classify a day's market trend as either bullish, bearish or reversal using OHLC and technical indicators as input features. With extensive work done on the data of NYSE, the modelling was done using various classification algorithms and dimensionality reduction techniques in order to develop the best classifier.

## Histopathologic Cancer Detection via Image Classification 
This project was my first breakthrough into image detection where I implemented a basic CNN to detect the images which might be prone to developing cancer in them. The neural network was trained on my NVIDIA gpu and image processing was tested using desaturation and rasterisation. 



